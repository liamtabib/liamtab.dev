---
title: "Historical Document Processor"
description: "Tool that takes pdf scans, validates the text quality, and builds clean datasets"
date: "Mar 18 2024"
repoURL: "https://github.com/liamtabib/historical-docs-processor"
---

During my work at KbLab, I built a tool that takes raw newspaper scans, validates the text quality, and builds clean datasets. The work is free to use and is suitable for historical research purposes, but also for curating data for LLM training.

## Features

- **Raw Scan Processing**: Handles raw newspaper scans and digitized documents
- **Text Quality Validation**: Validates and ensures high-quality text extraction
- **Clean Dataset Creation**: Builds structured, clean datasets from processed documents
- **Historical Research Ready**: Optimized for historical research applications
- **LLM Training Compatible**: Suitable for curating data for language model training
- **Open Source**: Free to use and publicly available under MIT license

## Tech Stack

- **APIs**: Integration with various document processing APIs
- **OCR**: Optical Character Recognition for text extraction
- **AI**: AI-powered text validation and quality assessment
- **Data Processing**: Robust data cleaning and structuring pipelines

## Impact

This tool enables researchers and developers to efficiently process large volumes of historical documents, making them accessible for both academic research and modern AI applications. It bridges the gap between historical archives and contemporary data science needs.

This project demonstrates my ability to work with complex document processing pipelines, OCR technologies, and data curation systems while contributing to open-source historical preservation efforts.